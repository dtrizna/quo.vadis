{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrijs.trizna/.pyenv/versions/3.8-dev/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score\n",
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import time\n",
    "repo_root = \"/data/quo.vadis/\"\n",
    "sys.path.append(repo_root)\n",
    "from models import CompositeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composite preprocessing of adversarial set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull adversarial emulation reports:  5399\n",
      "Errored adversarial emulation reports:  3497\n",
      "Total adversarial samples:  8896\n",
      "Emulation success rate: 60.69%\n"
     ]
    }
   ],
   "source": [
    "adversarial_testset_path = repo_root + \"data/adversarial.emulation.dataset/reports_ember\"\n",
    "adversarial_testset_files = os.listdir(adversarial_testset_path)\n",
    "adversarial_reports = [x.rstrip(\".json\") for x in adversarial_testset_files if x.endswith(\".json\")]\n",
    "print(\"Successfull adversarial emulation reports: \", len(adversarial_reports))\n",
    "adversarial_errors = [x for x in adversarial_testset_files if x.endswith(\".err\")]\n",
    "print(\"Errored adversarial emulation reports: \", len(adversarial_errors))\n",
    "print(\"Total adversarial samples: \", len(adversarial_errors) + len(adversarial_reports))\n",
    "print(f\"Emulation success rate: {len(adversarial_reports)/(len(adversarial_reports)+len(adversarial_errors))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE - there is less total samples because we skipped benignware and malware that was already evasive!\n",
    "\n",
    "Total file number match with filesystem data:\n",
    "```\n",
    "/data/quo.vadis/adversarial/samples_adversarial_testset_gamma_ember]$ find . -type f | wc -l\n",
    "8896\n",
    "```\n",
    "\n",
    "Adversarial length match with report_db in emulation module - it loads reports from `data/adversarial.emulation.dataset/reports_ember` since passed as parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5399"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = CompositeClassifier(modules=[\"emulation\"], repo_root=repo_root,\n",
    "                        emulation_report_path=\"data/adversarial.emulation.dataset/reports_ember\",)\n",
    "len(a.modules[\"emulation\"].report_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3 early_fusion_pass.py\n",
    "x_adv_ember = np.load(repo_root+\"evaluation/adversarial/composite_adversarial_evaluation/ember_15sections_10population/X-gamma-vs-ember-early-fusion-pass.arr\") \n",
    "x_orig_ember = np.load(repo_root+\"evaluation/adversarial/composite_adversarial_evaluation/ember_15sections_10population/X-gamma-vs-ember-early-fusion-pass-orig.arr\")\n",
    "\n",
    "# python3 run_ember_pass.py\n",
    "y_ember_orig = np.load(repo_root+\"evaluation/adversarial/composite_adversarial_evaluation/ember_15sections_10population/y-gamma-vs-ember-scores-orig.arr\")\n",
    "y_ember_adv = np.load(repo_root+\"evaluation/adversarial/composite_adversarial_evaluation/ember_15sections_10population/y-gamma-vs-ember-scores.arr\")\n",
    "EMBER_THRESHOLD = 0.8336\n",
    "y_ember_orig_int = (y_ember_orig > EMBER_THRESHOLD).astype(int)\n",
    "y_ember_adv_int = (y_ember_adv > EMBER_THRESHOLD).astype(int)\n",
    "\n",
    "x_train = np.load(repo_root+\"evaluation/composite/X-1647041985-early-fusion-vectors-train.arr\")\n",
    "y_train = np.load(repo_root+\"evaluation/composite/y-1647041985-train.arr\")\n",
    "\n",
    "x_test = np.load(repo_root+\"evaluation/composite/X-1647097165-early-fusion-vectors-test.arr\")\n",
    "y_test = np.load(repo_root+\"evaluation/composite/y-1647097165-test.arr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(models, x_trains, y_train, save=False):\n",
    "    for model in models:\n",
    "        print(f\"training late fusion model for {model}...\")\n",
    "        now = time.time()\n",
    "        models[model].fit(x_trains[model], y_train)\n",
    "        print(f\"training done for {model}... took: {time.time()-now:.2f}s\")\n",
    "        if save:\n",
    "            os.makedirs(\"late_fusion_model_fit\", exist_ok=True)\n",
    "            models[model].save_late_fusion_model(filename=\"late_fusion_model_fit/\"+model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training late fusion model for malconv...\n",
      "training done for malconv... took: 0.19s\n",
      "training late fusion model for filepaths...\n",
      "training done for filepaths... took: 0.23s\n",
      "training late fusion model for emulation...\n",
      "training done for emulation... took: 0.30s\n",
      "training late fusion model for ember...\n",
      "training done for ember... took: 0.26s\n",
      "training late fusion model for ember_emulation...\n",
      "training done for ember_emulation... took: 0.29s\n",
      "training late fusion model for ember_filepaths_emulation...\n",
      "training done for ember_filepaths_emulation... took: 0.34s\n",
      "training late fusion model for all...\n",
      "training done for all... took: 0.38s\n"
     ]
    }
   ],
   "source": [
    "# need to modify report path to original dataset\n",
    "modulelist = [[\"malconv\"], [\"filepaths\"], [\"emulation\"], [\"ember\"],\n",
    "            [\"ember\", \"emulation\"],\n",
    "            [\"ember\", \"filepaths\", \"emulation\"],\n",
    "            [\"malconv\", \"ember\", \"filepaths\", \"emulation\"]]\n",
    "models = {}\n",
    "x_trains = {}\n",
    "x_tests = {}\n",
    "\n",
    "x_ember_orig = {}\n",
    "x_ember_adv = {}\n",
    "\n",
    "for modules in modulelist:\n",
    "    name = \"_\".join(modules)\n",
    "    if len(modules) == 4:\n",
    "        name = \"all\"\n",
    "\n",
    "    models[name] = CompositeClassifier(modules=modules, late_fusion_model=\"LogisticRegression\", root=repo_root)\n",
    "    x_trains[name] = models[name].get_modular_x(modules, x_train)\n",
    "    x_tests[name] = models[name].get_modular_x(modules, x_test)\n",
    "    \n",
    "    x_ember_orig[name] = models[name].get_modular_x(modules, x_orig_ember)\n",
    "    x_ember_adv[name] = models[name].get_modular_x(modules, x_adv_ember)\n",
    "    \n",
    "    if \"ember\" in modules:\n",
    "        ember_index = modules.index(\"ember\")\n",
    "        # replace ember column with y pass\n",
    "        x_ember_orig[name][:,ember_index] = y_ember_orig\n",
    "        x_ember_adv[name][:,ember_index] = y_ember_adv\n",
    "\n",
    "# Remember: this .fit() really trains only late fusion model\n",
    "models = fit(models, x_trains, y_train, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== ember (secml) ======\n",
      "Non-Adversarial Set accuracy: 0.9814780514910169\n",
      "Adversarial Set accuracy:     0.7193924800889053\n",
      "\n",
      " ====== malconv ======\n",
      "Non-Adversarial Set accuracy: 0.9855528801629931\n",
      "Adversarial Set accuracy:     0.9803667345804778\n",
      "\n",
      " ====== filepaths ======\n",
      "Non-Adversarial Set accuracy: 0.9781441007593998\n",
      "Adversarial Set accuracy:     0.9781441007593998\n",
      "\n",
      " ====== emulation ======\n",
      "Non-Adversarial Set accuracy: 0.9955547323578441\n",
      "Adversarial Set accuracy:     0.9764771253935914\n",
      "\n",
      " ====== ember ======\n",
      "Non-Adversarial Set accuracy: 1.0\n",
      "Adversarial Set accuracy:     0.8705315799222079\n",
      "\n",
      " ====== ember_emulation ======\n",
      "Non-Adversarial Set accuracy: 0.9990739025745509\n",
      "Adversarial Set accuracy:     0.9562882015187998\n",
      "\n",
      " ====== ember_filepaths_emulation ======\n",
      "Non-Adversarial Set accuracy: 0.9887016114095203\n",
      "Adversarial Set accuracy:     0.9851824411928135\n",
      "\n",
      " ====== all ======\n",
      "Non-Adversarial Set accuracy: 0.9887016114095203\n",
      "Adversarial Set accuracy:     0.9851824411928135\n"
     ]
    }
   ],
   "source": [
    "def get_metrics_adv_nonadv(model, x_test, y_test, x_adv, y_adv):\n",
    "    probs = model.predict_proba(x_test)[:,1]\n",
    "    probs_adv = model.predict_proba(x_adv)[:,1]\n",
    "    \n",
    "    preds = np.where(probs > 0.5, 1, 0)\n",
    "    preds_adv = np.where(probs_adv > 0.5, 1, 0)\n",
    "\n",
    "    print(\"Non-Adversarial Set accuracy:\", end=\" \")\n",
    "    print(accuracy_score(y_test, preds))\n",
    "    #print(classification_report(y_test, preds, zero_division=0))\n",
    "    \n",
    "    print(\"Adversarial Set accuracy:\", end=\"     \")\n",
    "    print(accuracy_score(y_adv, preds_adv))\n",
    "    #print(classification_report(y_adv, preds_adv, zero_division=0))\n",
    "    return probs, probs_adv\n",
    "\n",
    "y_adv = np.ones(len(x_adv_ember))\n",
    "\n",
    "print(\"====== ember (secml) ======\")\n",
    "print(\"Non-Adversarial Set accuracy:\", end=\" \")\n",
    "print(accuracy_score(y_adv, y_ember_orig_int))\n",
    "print(\"Adversarial Set accuracy:\", end=\"     \")\n",
    "print(accuracy_score(y_adv, y_ember_adv_int))\n",
    "\n",
    "probbs, probbs_adv = {}, {}\n",
    "for model in models:\n",
    "    x_orig_t = x_ember_orig[model]\n",
    "    x_adv_t = x_ember_adv[model]\n",
    "    print(\"\\n\", \"=\"*6, model, \"=\"*6)\n",
    "    probbs[model], probbs_adv[model] = get_metrics_adv_nonadv(models[model], x_orig_t, y_adv, x_adv_t, y_adv)\n",
    "    # get_metrics_adv_nonadv(models[model], x_test_t, y_test, x_adv_t, y_adv) if you want against full set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100: ember (secml) classifies as benign in orig malware set\n",
      " 1515: ember (secml) classifies as benign in adversarial malware set\n",
      " 1415, 26.21%: evasive samples and ratio against ember\n",
      "\n",
      " 78: malconv classifies as benign in orig malware set\n",
      " 106: malconv classifies as benign in adversarial malware set\n",
      " 28, 0.52%: evasive samples and ratio against malconv \n",
      "\n",
      " 118: filepaths classifies as benign in orig malware set\n",
      " 118: filepaths classifies as benign in adversarial malware set\n",
      " 0, 0.00%: evasive samples and ratio against filepaths \n",
      "\n",
      " 24: emulation classifies as benign in orig malware set\n",
      " 127: emulation classifies as benign in adversarial malware set\n",
      " 103, 1.91%: evasive samples and ratio against emulation \n",
      "\n",
      " 0: ember classifies as benign in orig malware set\n",
      " 699: ember classifies as benign in adversarial malware set\n",
      " 699, 12.95%: evasive samples and ratio against ember \n",
      "\n",
      " 5: ember_emulation classifies as benign in orig malware set\n",
      " 236: ember_emulation classifies as benign in adversarial malware set\n",
      " 231, 4.28%: evasive samples and ratio against ember_emulation \n",
      "\n",
      " 61: ember_filepaths_emulation classifies as benign in orig malware set\n",
      " 80: ember_filepaths_emulation classifies as benign in adversarial malware set\n",
      " 19, 0.35%: evasive samples and ratio against ember_filepaths_emulation \n",
      "\n",
      " 61: all classifies as benign in orig malware set\n",
      " 80: all classifies as benign in adversarial malware set\n",
      " 19, 0.35%: evasive samples and ratio against all \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\" {((y_ember_orig_int).astype(int) == 0).sum()}: ember (secml) classifies as benign in orig malware set\")\n",
    "print(f\" {((y_ember_adv_int).astype(int) == 0).sum()}: ember (secml) classifies as benign in adversarial malware set\")\n",
    "evasive = ((y_ember_adv_int).astype(int) == 0).sum() - ((y_ember_orig_int).astype(int) == 0).sum()\n",
    "evasive_ratio = evasive*100/len(y_ember_adv_int)\n",
    "print(f\" {evasive}, {evasive_ratio:.2f}%: evasive samples and ratio against ember\")\n",
    "print()\n",
    "\n",
    "for model in models:\n",
    "    orig_benign = ((probbs[model] > 0.5).astype(int) == 0).sum()\n",
    "    adv_benign = ((probbs_adv[model] > 0.5).astype(int) == 0).sum()\n",
    "    evasive = adv_benign - orig_benign\n",
    "    evasive_ratio = evasive*100/len(probbs[model])\n",
    "    print(f\" {orig_benign}: {model} classifies as benign in orig malware set\")\n",
    "    print(f\" {adv_benign}: {model} classifies as benign in adversarial malware set\")\n",
    "    print(f\" {evasive}, {evasive_ratio:.2f}%: evasive samples and ratio against {model} \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC curves (DRAFT, might no be needed)\n",
    "\n",
    "Possible only if - ROC evaluation if forming a validation set with benign labels, but replacing original malware with adversarial samples if they were acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "modulelist = [[\"malconv\"], [\"ember\"], [\"emulation\"], [\"malconv\", \"ember\", \"filepaths\", \"emulation\"]]\n",
    "mmodels = {}\n",
    "for x in modulelist:\n",
    "    key = \"_\".join(x)\n",
    "    if key == \"malconv_ember_filepaths_emulation\":\n",
    "        key = \"All\"\n",
    "    mmodels[key] = models[key]\n",
    "\n",
    "def evaluate_adversarial_robustness(models, x_tests, x_tests_adv, y_test, y_test_adv, ax=None):\n",
    "    probs = {}\n",
    "    probs_adv = {}\n",
    "\n",
    "    model = \"No Skill\"\n",
    "    most_common_label = np.argmax(np.bincount(y_test.astype(int)))\n",
    "    probs[model] = np.array([most_common_label for _ in range(len(y_test))], dtype=int)\n",
    "    probs_adv[model] = np.array([most_common_label for _ in range(len(y_test_adv))], dtype=int)\n",
    "    \n",
    "    _, ax = plt.subplots(2, 2, figsize=(14,12))\n",
    "    ax_idx = {0: [0,0], 1: [0,1], 2: [1,0], 3:[1,1], 4:[2,0], 5:[2,1]}\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        i1, i2 = ax_idx[i][0],ax_idx[i][1]\n",
    "        probs[model] = models[model].predict_proba(x_tests[model])[:,1]\n",
    "        probs_adv[model] = models[model].predict_proba(x_tests_adv[model])[:,1]\n",
    "        # preds = np.where(probs[model] > 0.5, 1, 0)\n",
    "        # preds_adv = np.where(probs_adv[model] > 0.5, 1, 0)\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(y_test, probs[model])\n",
    "        fpr_adv, tpr_adv, _ = roc_curve(y_test_adv, probs_adv[model])\n",
    "        # plot the roc curve for the model\n",
    "        linestyle = \"--\" if model == \"No Skill\" else \"solid\"\n",
    "        ax[i1,i2].plot(fpr, tpr, linestyle=linestyle, label=model)\n",
    "        ax[i1,i2].plot(fpr_adv, tpr_adv, linestyle=linestyle, label=model)\n",
    "        # axis labels\n",
    "        ax[i1,i2].set_xlabel('False Positive Rate')\n",
    "        ax[i1,i2].set_ylabel('True Positive Rate')\n",
    "        ax[i1,i2].title.set_text(model)\n",
    "        _ = ax[i1,i2].legend([\"regular\", \"adversarial\"])\n",
    "        # TBD - set legend position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of different attack -- per number of sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
